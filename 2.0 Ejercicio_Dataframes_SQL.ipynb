{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2c6ce4e",
   "metadata": {},
   "source": [
    "# Ejercicio aplicado de DataFrames y Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ce61a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pandas as pd\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea15104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "        .master(\"local[*]\")\\\n",
    "        .appName('PySpark_Df')\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285645dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importa el csv de \"data/WorldCupPlayers.csv\"\n",
    "## Visualiza los datos\n",
    "df = spark.read.csv (\"C:/Users/Manuel/Desktop/Pyspark/data/WorldCupPlayers.csv\", \n",
    "                          inferSchema = True, \n",
    "                          header = True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ff1bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ¿que tipo de datos contiene cada variable?\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ca7728",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ¿Cuantos registros hay?\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb71fdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Obtén los principales estadísticos de Position\n",
    "df.describe('Position').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1a39f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selecciona y muestra los registros distintos de 'Player Name','Coach Name'\n",
    "df.select('Player Name','Coach Name').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8ab2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ¿Cuantos partidos con el ID de 1096 ha habido?\n",
    "df.filter(df.MatchID =='1096').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3cbdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Muestra los datos donde la posicion haya sido C y el evento sea G40\n",
    "df.filter((df.Position == 'C') & (df.Event==\"G40'\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dda94a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utiliza Spark SQL para mostras los registros donde el MatchID sea mayor o igual a 20\n",
    "table = df.createOrReplaceTempView(\"temp_table\")\n",
    "spark.sql(\"select * from temp_table where MatchID >= 20\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cab5468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark_int = SparkSession.builder\\\n",
    "        .master(\"local[*]\")\\\n",
    "        .appName('PySpark_Df')\\\n",
    "        .getOrCreate()\n",
    "\n",
    "data = [(\"James\",\"null\",\"Smith\",\"36636\",\"M\",60000),\n",
    "        (\"Michael\",\"Rose\",\"null\",\"40288\",\"M\",70000),\n",
    "        (\"Robert\",\"null\",\"Williams\",\"42114\",\"null\",400000),\n",
    "        (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",500000),\n",
    "        (\"Jen\",\"Mary\",\"Brown\",\"null\",\"F\",0)]\n",
    "\n",
    "columns = [\"first_name\",\"middle_name\",\"last_name\",\"dob\",\"gender\",\"salary\"]\n",
    "\n",
    "df = spark_int.createDataFrame(data = data, schema = columns)\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a8ef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import findspark, pyspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b16db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_core = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fdb0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(1, \"AAA\", \"dept1\", 1000),\n",
    "        (2, \"BBB\", \"dept1\", 1100),\n",
    "        (3, \"CCC\", \"dept1\", 3000),\n",
    "        (4, \"DDD\", \"dept1\", 1500),\n",
    "        (5, \"EEE\", \"dept2\", 8000),\n",
    "        (6, \"FFF\", \"dept2\", 7200),\n",
    "        (7, \"GGG\", \"dept3\", 7100),\n",
    "        (8, \"HHH\", \"dept3\", 3700),\n",
    "        (9, \"III\", \"dept3\", 4500),\n",
    "        (10, \"JJJ\", \"dept5\", 3400)]\n",
    "\n",
    "dept = [(\"dept1\", \"Departament - 1\"),\n",
    "        (\"dept2\", \"Departament - 2\"),\n",
    "        (\"dept3\", \"Departament - 3\"),\n",
    "        (\"dept4\", \"Departament - 4\")]\n",
    "\n",
    "df = spark_core.createDataFrame(data, [\"id\", \"name\", \"dept\", \"salary\"])\n",
    "df2 = spark_core.createDataFrame(dept, [\"id\",\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43258856",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6164837",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feb6907",
   "metadata": {},
   "source": [
    "# Operaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee00941",
   "metadata": {},
   "source": [
    "##### Count\n",
    "- Cuenta el numero de filas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa32a119",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c71e5eb",
   "metadata": {},
   "source": [
    "##### Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ebd9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef27e94",
   "metadata": {},
   "source": [
    "##### dtypes\n",
    "- Accede al datatype de columnas dentro del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbda9786",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f53208",
   "metadata": {},
   "source": [
    "##### schema\n",
    "- Comprueba como Spark almacena el esquema del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c608f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39ee4ad",
   "metadata": {},
   "source": [
    "##### printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0885dc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df37b0b",
   "metadata": {},
   "source": [
    "##### select\n",
    "- seleccione columnas del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f543b94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"id\", \"name\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ff7ba6",
   "metadata": {},
   "source": [
    "##### filter\n",
    "- Filtrar las filas segun alguna condicion.\n",
    "- intentemos encontrar las filas con id = 1\n",
    "- Hay diferentes formas de especificar la condicion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaa1033",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(df[\"id\"] == 1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091cd7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(df.id == 1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2b6420",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(col(\"id\") == 1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c7f98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(\"id = 1\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2508faa0",
   "metadata": {},
   "source": [
    "##### drop\n",
    "- Elimina una columna en particular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13366e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = df.drop(\"id\")\n",
    "newdf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af1645e",
   "metadata": {},
   "source": [
    "##### Aggregations\n",
    "- Podemos usar la funcion groupBy para agrupar los datos y luego usar la funcion \"agg\" para realizar la agregacion de datos agrupados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f1c7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modify = df.groupBy(\"dept\") \\\n",
    "    .agg(\n",
    "        count(\"salary\").alias(\"count\"),\n",
    "        sum(\"salary\").alias(\"sum\"),\n",
    "        max(\"salary\").alias(\"max\"),\n",
    "        min(\"salary\").alias(\"min\"),\n",
    "        avg(\"salary\").alias(\"avg\")\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c766ca",
   "metadata": {},
   "source": [
    "##### Sorting \n",
    "- Ordena los datos segun el \"salario\". De forma predeterminada.\n",
    "- La clasificacion se realiza en orden ascendente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3ab07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort(\"salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84322729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the data in descendig orden\n",
    "df.sort(desc(\"salary\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1385ac4",
   "metadata": {},
   "source": [
    "##### Columnas derivadas\n",
    "- Podemos usar la funcion \"withColumn\" para derivar la columa en funcion de las columnas existentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d03aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn(\"bonus\", col(\"salary\") * .1).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.17 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "944c19f52a24f95874af1a0965923405492a6b817585bc3c2ef5cb7556d69262"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
